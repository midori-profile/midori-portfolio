---
title: "Mastering CI/CD: A Beginner’s Guide to K8s Resource Management"
publishedAt: '2023-10-28'
summary: 'Understand the resources in k8s and how to manipulate them'
---
## Background:

For many who are new to CI/CD and starting with GitHub Actions, the most significant challenge is quickly understanding the variety of resources and concepts within Kubernetes (k8s). 

Questions like "What are deployments, ingress?" and "What's the difference between a container and a container image?" may initially seem daunting.

This presentation is beginner-friendly! I will explain everything in the simplest terms or metaphor to ensure it's easy to understand. Let's dive in.

## I. The concept of Kubernetes (k8s) & its overall architecture.

**Use one sentence to summarize:** 
> It's a system for automating the deployment, scaling, and management of containerized apps.

but, what does that really mean?

Picture this: 

you've got a bunch of apps or services that need to run, and they often need attention—like starting, stopping, or updating. You don't want to do this manually every single time, right?

This is where Kubernetes really shines! You can think of it as an automated army of robots to manage your applications.


### I will briefly introduce the basic concept of Kubernetes (k8s) first:

#### The most fundamental concept:

In k8s is the **container**. Simply put, a container is like a lightweight, encapsulated software package that contains everything needed to run an application: code, runtime environment, libraries, and even system settings. 
It's like packing your application into a portable box that can run anywhere.

Then, k8s comes in to manage these boxes. It ensures that the containers run in the right places and automatically adjusts their numbers as needed (this is what is called scaling). For instance, if the number of users of your application suddenly increases, k8s can automatically strengthen support by adding more containers to share the load. Conversely, if the number of users decreases, it will reduce the number of containers accordingly.

#### Core Architecture of K8s:

1. **Master Node**: The brain of the entire k8s system. It decides where the containers should run and when to scale them.
2. **Worker Node**: These nodes do the actual work, running your containers. They carry Pods.
3. **Container**: The smallest unit in k8s, the simplest running unit of an application.
4. **Pod**: Think of it as a home for containers. Usually, a Pod runs a single container, but sometimes, closely related containers may share a Pod.
5. **Ingress**: Manages the rules for external access to your applications, such as routing HTTP traffic.
6. **Service**: Defines how a group of Pods can be accessed. It provides Pods with a fixed IP address and DNS name.
> **Difference between Ingress and Service**
> - Ingress is like a public highway leading into a neighborhood. It manages and directs external traffic coming from outside the cluster to the appropriate Services within the cluster.
> - Service is like the internal GPS mapping service. It ensures that anyone who wants to visit a house (Pod) can find it easily, even if the house moves locations.
7. **Deployment**: Helps you manage Pods and ensures that the specified number of Pods are always running.


These components work together to enable Kubernetes

If you find it difficult to grasp so many concepts all at once, never mind. you will quickly understand them in the （Using kubectl to Operate Resources and View These Resources in Rancher）(third) part.

## II. Understanding Common Kubernetes Resources

now, we'll introduce common Kubernetes resources. Understanding these will prevent you from feeling lost when writing most CI jobs, as the resources you'll encounter in work mostly fall within this scope.


### Containers and Pods

- **Container**: The smallest deployable unit in a Kubernetes application, similar to a single process in a traditional operating system.
    - **Container Image**: A self-contained package that includes everything needed to run a container, analogous to a class in programming.
    - **Container Instance**: The running version of a container image, similar to an instance of a class.

- **Pod**: A group of one or more containers, with shared storage/network, and a specification on how to run the containers. Think of a Pod as a home for containers, akin to a process group in an operating system.

> **Pods Key Points**:
> - Containers within a Pod share the same IP address and can communicate using `localhost`.
> - Kubernetes can automatically manage the lifecycle of Pods, restarting or replacing them as necessary.

### ReplicaSet

A ReplicaSet ensures a specified number of pod replicas are running at any given time, aiding in application scaling and fault tolerance.

> **How a ReplicaSet Works**:
> - Defined by a **Selector**, **Number of Replicas**, and a **Pod Template**.
> - Acts like a manager, maintaining the desired state of pod replicas.

### Deployment

Deployments manage the deployment and scaling of a set of Pods, and provide declarative updates to Pods and ReplicaSets.

> **Core Concepts of Deployment**:
> - **Declarative Updates**: You define the desired state, and Kubernetes makes it happen.
> - **Rollouts and Rollbacks**: Automate updates and rollbacks, maintaining application availability.
> - **Scalability**: Easily scale applications up or down based on demand.

### Job and CronJob

- **Job**: Executes tasks that terminate upon completion, like batch jobs or data processing tasks.
- **CronJob**: Schedules tasks to run at specified times, useful for periodic tasks like backups or sending emails.

### Networking: Ingress and Service

- **Ingress**: Manages external access to your services, acting as a router or HTTP proxy.
- **Service**: Provides a consistent way to access a group of Pods, serving as internal load balancers.

> **Service vs. Ingress**:
> - **Ingress** is like a public highway into your application, directing incoming traffic.
> - **Service** is like an internal GPS, ensuring connections find their way to the right Pods.

### Storage: Volume and Secrets

- **Volume**: Allows data to persist and be shared between containers in a Pod, separating data lifecycle from container lifecycle.
- **Secrets**: Manages sensitive information, providing a secure way to store and access passwords, tokens, and keys.


## III. Getting started right now → Using kubectl to Operate Resources and View These Resources in Rancher

基于你的要求，以下是经过格式化处理的 Markdown 文档，其中包含了代码段和其他元素的清晰展示：

```markdown
## Getting Started with `kubectl` and Rancher

### Introduction

- **kubectl**: The command-line tool that lets you control Kubernetes clusters.
- **Rancher**: An open-source platform for managing Kubernetes, offering a UI for Kubernetes (k8s) environments.

> **Note**: Although Rancher provides a convenient UI, mastering `kubectl` is crucial for direct cluster management and debugging. Sometimes, Rancher might not display all the necessary information for troubleshooting.

### Connecting to a Kubernetes Playground with `kubectl`

A "Playground" refers to a Kubernetes environment set up for learning and testing. It allows users to experiment with Kubernetes features without affecting production environments.

1. Download your `kubeconfig` file from [Rancher Monitoring](https://rancher.unext.dev/c/c-7wgx6/monitoring) and save it to `~/.kube/config`. This configures `kubectl` to interact with your cluster.

### Basic `kubectl` Commands

- To view all resources in your namespace (Deployments, Services, Pods, etc.):

    ```bash
    kubectl get all -n webfront
    ```

- To view all pods in your namespace:

    ```bash
    kubectl get pods -n webfront
    ```

### Understanding Pod Information

Example output:

```plaintext
u-github-runner-webfront-docker-5ddf45d5f6-nbvxk 1/1 Running 0 148m
```

Explanation:

- `1/1`: The number of replicas.
- `Running`: The Pod's status.
- `0`: The current restart count.
- `148m`: The duration the Pod has been running.

### Deploying a Stateless Application

- **Objective**: Run five instances of a "Hello World" application and expose it externally.

1. Create a deployment with the following YAML (`load-balancer-example.yaml`):

    ```yaml
    apiVersion: apps/v1
    kind: Deployment
    metadata:
      labels:
        app.kubernetes.io/name: load-balancer-example
      name: hello-world
    spec:
      replicas: 5
      selector:
        matchLabels:
          app.kubernetes.io/name: load-balancer-example
      template:
        metadata:
          labels:
            app.kubernetes.io/name: load-balancer-example
        spec:
          containers:
          - image: gcr.io/google-samples/node-hello:1.0
            name: hello-world
            ports:
            - containerPort: 8080
    ```

    Apply the deployment:

    ```bash
    kubectl apply -f load-balancer-example.yaml -n webfront
    ```

2. Expose the deployment:

    ```bash
    kubectl expose deployment hello-world --type=LoadBalancer --name=hello-world-service -n webfront
    ```

3. View the service:

    ```bash
    kubectl get services hello-world-service -n webfront
    ```

    Output example:

    ```plaintext
    NAME                  TYPE           CLUSTER-IP     EXTERNAL-IP      PORT(S)          AGE
    hello-world-service   LoadBalancer   10.96.57.137   10.231.201.240   8080:30555/TCP   24s
    ```

4. Access the application:

    ```bash
    curl http://10.231.201.240:8080
    ```

    Successful response: A "hello message".

🎉 Congratulations! You've successfully deployed your first application using `kubectl`.
